---
title: "Technology Radar Volume 32 まとめ"
emoji: "🔖"
type: "tech" # tech: 技術記事 / idea: アイデア
topics: [technologyradar, curation]
published: true
publication_name: "beingish"
---

[2025 年 4 月 3 日公開](https://www.thoughtworks.com/content/dam/thoughtworks/documents/radar/2025/04/tr_technology_radar_vol_32_en.pdf)。

https://www.thoughtworks.com/radar

[Technology Radar についてはここにまとめている](https://zenn.dev/januswel/articles/d3b2c23bcbcd6f)。

この記事では次のことがわかる。

1. 今号のテーマ
2. 各カテゴリーごとの Adopt / Hold / ピックアップを紹介
   - ピックアップは将来的に影響がありそうなものや面白そうなものを選んでいる
   - 個人的な思いなども書いているので参考に

## その他のまとめ

- [Volume 28](https://zenn.dev/beingish/articles/93d6a1a62ba100)
- [Volume 29](https://zenn.dev/beingish/articles/edb33ee3775169)
- [Volume 30](https://zenn.dev/beingish/articles/554260542fced5)
- [Volume 31](https://zenn.dev/beingish/articles/b6f6ae477c7ea2)

## 今号のテーマ

### Supervised agents in coding assistants: コーディングアシスタントにおける指示駆動型エージェント

Cursor や Cline など IDE に組み込まれたエージェントが良さそう、というテーマ。人間が都度、口を差し挟めるというのが使いやすくて良いというニュアンスが書かれている。

同時に注意点も書かれているが、人間がすべてわかったうえで指示を出してやる必要がある。すべてエージェントが組んでくれるが、できたものを使うかどうかは使用者の責任だ。実用的なものほど対象領域の知識、アーキテクチャー、コード、ファイルパーミッション、 IoC 設定など広範な知識が求められる。原文の最後の <q>With great power…</q> というのはスパイダーマンで出てくるセリフで、全文は次だ。

> With great power comes great responsibility.

エージェントが求めてくる許可についても同様だがいまのやり方は許可を出す側も疲れる。 Deno のように実行時に許可する権限を指定する、ガードレールのようなものでエージェントが操作できる範囲をあらかじめ決めておくなど、補助的な仕組みは早晩揃うだろう。

なお Devin などコーディングアシスタントではなく、独立したプロセスとしてコード生成するのはムダが多いと感じている。 PR 段階で指摘をいれるのは品質の作り込みや教育における情報伝達においてロスが大きすぎる。より早い段階、コードを書く時点で密にやりとりするほうがリソースの使い方として有用だろう。

これからの課題は使いこなせるレベルに達するまでのロードマップ策定や知識 / スキルのトランスファーなど、いわゆる教育だろうか。こればっかりは人間 2 人とエージェント 1 人でのプログラミングなどで地道にやっていくしかない気がしている。良いプラクティスは出てくるだろうが基本路線は変わらない可能性も高い。

### Evolving observability: 進化する可観測性

OpenTelemetry の普及によってツール選択の自由が獲得されたこと、 LLM など大容量のコンテキストを飲み込めるツールによって分析が捗ることのふたつが挙げられている。

LLM による複雑なデータの分析は相性が良いらしく、今号では折に触れて似たような事例が報告されている。

### R in RAG: RAG の Retrieval 処理

RAG: Retrieval-Augumented Generation の Retrieval 部分、つまり回答文生成の元データとなる部分の取得についてかなり進展があるとのこと。具体的なものとして次が挙げられている。

- corrective RAG
- Fusion-RAG
- Self-RAG
- FastGraphRAG

### Taming the data frontier: データの未開領域を使いこなす

非構造化データなど読み解くのが難しかったデータを LLM によって扱いやすくなってきている。

より目的に叶う形でのデータ活用がしやすくなったということが書かれている。

## Techniques

### Adopt

#### Data product thinking: データを製品として考える

顧客の目的に合致するようにそのデータの提供や分析の方法をともに模索する考え方のことを言うらしい。

https://www.thoughtworks.com/insights/e-books/modern-data-engineering-playbook/data-as-a-product

データを必要とする人間がデータを揃える、となると現実的でないこともあるためこの考え方が Adopt として紹介される時代になったのは良いことだろう。ただ、データの源泉を考えると意味のある活動をしている主体に、さらにこういったコストを上乗せする場面も多くなる気がするので、やり方の共有やツールによる補助などが進展するとうれしい blip 。

#### Fuzz testing: ファズテスト

https://ja.wikipedia.org/wiki/%E3%83%95%E3%82%A1%E3%82%B8%E3%83%B3%E3%82%B0

動くものに対してツールで無効なデータを入力していき、クリティカルな状態にならないかやメモリーリークを起こさないかなどを確認していく手法のことらしい。

生成 AI によってコードを生成する機会が多くなったことで相対的に重要性が上がっていると記載されている。のだが、品質の作り込みとは逆の方向性なのでメンタルモデルの変更は必須だろう。富豪的にそれっぽいものを生成したあとで、クリティカルな状態が発生しないことを確認していく。

#### Software Bill of Materials: SBOM

SBOM はサプライチェーン攻撃の台頭によって、依存ライブラリーに対してより自覚的になろうという意図で普及してきたものだ。

https://en.wikipedia.org/wiki/Supply_chain_attack#Ethereum_Smart_Contract_and_NPM_Library_typosquat_attack

最近では使用する生成 AI の依存についても把握した方が良いとのことで、また違った観点で注目されている。

#### Threat modeling: 脅威モデリング

システムを取り巻く脅威についてあらかじめ議論し、想定されるリスクについての共有とクリティカルなものへの対処をすることらしい。

https://martinfowler.com/articles/agile-threat-modelling.html

医療システムについてはリスク分析という形であらかじめやったりもするのだが、既存のシステムではコスパが悪い。やはりコードが生成されるものへとシフトしたことによってこういった手法に新たに焦点が当てられようになったという経緯なのだろう。

### Hold

#### AI-accelerated shadow IT: AI が加速する シャドー IT

生成 AI によってシャドー IT 増加の可能性が上がるが、きちんと把握していきましょう、という blip 。

https://en.wikipedia.org/wiki/Shadow_IT

個人的には中央集約的に管理は難しい時代になってきているので、セキュリティや法令遵守などについては最低ラインを担保しつつ、各チームレベルでうまくやってくださいね、という方向性が良いのではと考えている。

#### Complacency with AI-generated code: 生成されたコードへの過信

vibe coding などで当初の目的を果たす時間が非常に少なくなっているが、鵜呑みにするのは危ないよ、という blip 。

生成 AI を使いはじめると、クリティカルシンキングの対象が自分自身の思考やドメイン知識など前提データなどから、生成 AI の応答全般にすり替わり、クリティカルシンキングの数自体も減るらしい。

https://www.microsoft.com/en-us/research/publication/the-impact-of-generative-ai-on-critical-thinking-self-reported-reductions-in-cognitive-effort-and-confidence-effects-from-a-survey-of-knowledge-workers/

事例を収集して分析した結果らしいので、物珍しさやお手並み拝見という意識でこういった結果になっているのではないかとも受け取れる。

Cursor でコード生成させたらそれっぽいものを出力してくるものの、目的の深い理解をする前に生成しはじめたりメンテナンスに難のある結果になったりしたので、そこに目がいってしまいがちと感じた。経験が少ないエンジニアだと、出力量に圧倒されて当初の目的を果たせているかという観点がおざなりになってしまう可能性もある。

個人的に生成 AI は細かくタスクを分解した後に使うのが生成結果の確認も含めて楽な気がする。そうすると目的に対する戦略も練りやすいし、他の選択肢の検討やコードへの納得感、妥当なコードだという感覚も醸成されやすい。

本番投入は待て、と書いてあるが妥当だろう。

https://x.com/janus_wel/status/1884233866665447693

#### Local coding assistants: スタンドアロン型コーディングアシスタント

コーディングアシスタントは強力だが、秘密保持など企業の競争力向上やコンプライアンス準拠に関しては手放しで使えるものではない。こういった制約を満たしながらコーディングアシスタントを使いたいとなると、手元のマシンで動くモデルを使うしかない。しかし使い物になるモデルはクラスターで動かすような大仰なものとなるし、各社ともクラウドベースでの提供がメインなので現在はまだ様子見だ、という blip 。

DeepSeek などそれなりに手元で動くモデルも出てきたが、ここで問題になっているのはセキュリティなのでそれをクリアするのはしばらくかかるだろうという意味合いで Hold に位置していると思われる。

次巻 Volume 33 は半年後だが、そこで、もしくはそれよりも早く状況が変わうる blip だ。

#### Replacing pair programming with AI:

#### Reverse ETL:

#### SAFe™

### ピックアップ

## Platforms

### Adopt

#### GitLab CI/CD

#### Trino

### Hold

#### Tyk hybrid API management

### ピックアップ

## Tools

### Adopt

#### Renovate

#### uv

#### Vite

### Hold

なし。

### ピックアップ

## Languages & Frameworks

### Adopt

#### OpenTelemetry

#### React Hook Form

### Hold

#### Node overload

### ピックアップ
